{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b553fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b70c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"energy.txt\",sep=\"\\s+\")\n",
    "data=df.iloc[:,0:8]\n",
    "y=df.iloc[:,-1:]\n",
    "for col in data:\n",
    "    data.loc[data.sample(frac=0.1,random_state=None).index, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d155b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03196623780738176\n",
      "2.963508285505554\n",
      "0.016642123429232804\n",
      "2.37653374099159\n",
      "0.05313664756685322\n",
      "2.4068002628696483\n",
      "0.2729059265467133\n",
      "3.043224161698032\n",
      "0.2646621784835896\n",
      "2.441257633983395\n",
      "0.2713800087312525\n",
      "2.3195042736921314\n"
     ]
    }
   ],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X2=imp.fit(data)\n",
    "X2=imp.transform(data)\n",
    "X2=MinMaxScaler().fit_transform(X2)\n",
    "data01=df.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "MAE=np.abs(data01-X2)\n",
    "aa=MAE.mean()\n",
    "print(aa)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae11 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae11)\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "data01=df.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "MAE=np.abs(data01-train1)\n",
    "bb=MAE.mean()\n",
    "print(bb)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae12 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae12)\n",
    "mice_imputer = IterativeImputer()\n",
    "data01=df.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "X4= mice_imputer.fit_transform(data)\n",
    "X5=MinMaxScaler().fit_transform(X4)\n",
    "MAE=np.abs(data01-X5)\n",
    "cc=MAE.mean()\n",
    "print(cc)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X5, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae13 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae13)\n",
    "Z=data.copy(deep=True)\n",
    "Z[Z>=0]=0\n",
    "Z[Z<0]=0\n",
    "Z=Z.fillna(value=1)\n",
    "data2=pd.concat([data,Z],axis=1)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Z2=imp.fit(data2)\n",
    "Z2=imp.transform(data2)\n",
    "Z2=MinMaxScaler().fit_transform(Z2)\n",
    "data01=df.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "data02=np.append(data01,data01,axis=1)\n",
    "MAE=np.abs(data02-Z2)\n",
    "dd=MAE.mean()\n",
    "print(dd)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae14 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae14)\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data2)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data02-train1)\n",
    "ee=MAE.mean()\n",
    "print(ee)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae15 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae15)\n",
    "mice_imputer = IterativeImputer()\n",
    "Z1= mice_imputer.fit_transform(data2)\n",
    "Z3=MinMaxScaler().fit_transform(Z1)\n",
    "MAE=np.abs(data02-Z3)\n",
    "ff=MAE.mean()\n",
    "print(ff)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z3, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae16 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be036b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4\n",
      "0.015191406056237785\n",
      "2.3797772507440476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "imputer = MissForest()\n",
    "X_imputed = imputer.fit_transform(data)\n",
    "X_imputed=MinMaxScaler().fit_transform(X_imputed)\n",
    "MAE=np.abs(data01-X_imputed)\n",
    "gg=MAE.mean()\n",
    "print(gg)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae17 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86d763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.040727629484953703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3715678936982307"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import miceforest as mf\n",
    "import pandas as pd\n",
    "kernel = mf.ImputationKernel(\n",
    "  data=data,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "new_data = data.iloc[range(768)]\n",
    "new_data_imputed = kernel.impute_new_data(new_data)\n",
    "new_completed_data = new_data_imputed.complete_data(0)\n",
    "new_completed_data =MinMaxScaler().fit_transform(new_completed_data)\n",
    "MAE=np.abs(data01-new_completed_data)\n",
    "hh=MAE.mean()\n",
    "print(hh)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_completed_data, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae18 = mean_absolute_error(y_test, y_pred)\n",
    "mae18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d28020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)\n",
    "data1=df.iloc[:,0:8]\n",
    "#%% System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.1\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.0\n",
    "\n",
    "#%% Data\n",
    "\n",
    "# Data generation\n",
    "Data = data1\n",
    "# Parameters\n",
    "Data = np.array(Data,type(float))\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "#%% Necessary Functions\n",
    "\n",
    "# 1. Xavier Initialization Definition\n",
    "# def xavier_init(size):\n",
    "#     in_dim = size[0]\n",
    "#     xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "#     return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "#%% 1. Discriminator\n",
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 2. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx\n",
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample\n",
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ad382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed test data:\n",
      "[[0.58189421 0.83333333 0.42857143 ... 0.66666644 0.62499844 0.19999996]\n",
      " [0.24999931 0.66666666 0.14285714 ... 0.99999967 0.99999750 0.59991693]\n",
      " [0.00000000 1.00000000 0.71428571 ... 0.00000000 0.62499844 0.59999988]\n",
      " ...\n",
      " [0.24999931 0.66666666 0.14285714 ... 0.66666644 0.99999750 0.39999992]\n",
      " [0.38888781 0.50000000 0.41219505 ... 0.99999967 0.99999750 0.39999992]\n",
      " [0.05555540 0.91666666 0.57142857 ... 0.99999967 0.62499844 0.59999988]]\n",
      "0.36751025497911405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.363727326409732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "M_mb = M_mb.astype(float)\n",
    "X_mb = testX\n",
    "X_mb = X_mb.astype(float)\n",
    "\n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
    "print(\"Imputed test data:\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "if use_gpu is True:\n",
    "    print(imputed_data.cpu().detach().numpy())\n",
    "else:\n",
    "    print(imputed_data.detach().numpy())\n",
    "A=imputed_data.detach().numpy()\n",
    "MAE=np.abs(data01-A)\n",
    "ii=MAE.mean()\n",
    "print(ii)\n",
    "X_train, X_test, y_train, y_test = train_test_split(imputed_data.detach().numpy(), y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae19 = mean_absolute_error(y_test, y_pred)\n",
    "mae19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba4df9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09334006742912342\n",
      "4.2680087357791665\n",
      "0.016642123429232804\n",
      "2.37653374099159\n",
      "0.05313664756685322\n",
      "2.4068002628696483\n",
      "0.29771389635510404\n",
      "4.292706988784117\n",
      "0.27658353936735286\n",
      "3.159710899690548\n",
      "0.314272515981639\n",
      "3.0591402153237155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2\n",
      "0.04010661464126652 2.6150167211839386\n",
      "0.040727629484953703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3715678936982307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"energy.txt\",sep=\"\\s+\")\n",
    "dataa=df1.iloc[:,0:8]\n",
    "y=df1.iloc[:,-1:]\n",
    "for col in dataa :\n",
    "    dataa.loc[dataa.sample(frac=0.3,random_state=None).index, col] = np.nan\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "A2=imp.fit(dataa)\n",
    "A2=imp.transform(dataa)\n",
    "A2=MinMaxScaler().fit_transform(A2)\n",
    "data01=df1.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "MAE=np.abs(data01-A2)\n",
    "aa2=MAE.mean()\n",
    "print(aa2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(A2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae211 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae211)\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data01-train1)\n",
    "bb2=MAE.mean()\n",
    "print(bb2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae212 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae212)\n",
    "mice_imputer = IterativeImputer()\n",
    "A4= mice_imputer.fit_transform(data)\n",
    "A5=MinMaxScaler().fit_transform(A4)\n",
    "data02=np.append(data01,data01,axis=1)\n",
    "MAE=np.abs(data01-A5)\n",
    "cc2=MAE.mean()\n",
    "print(cc2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(A5, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae213 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae213)\n",
    "Z=dataa.copy(deep=True)\n",
    "Z[Z>=0]=0\n",
    "Z[Z<0]=0\n",
    "Z=Z.fillna(value=1)\n",
    "data2=pd.concat([dataa,Z],axis=1)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Z2=imp.fit(data2)\n",
    "Z2=imp.transform(data2)\n",
    "Z2=MinMaxScaler().fit_transform(Z2)\n",
    "data02=np.append(data01,data01,axis=1)\n",
    "MAE=np.abs(data02-Z2)\n",
    "dd2=MAE.mean()\n",
    "print(dd2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae214 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae214)\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data2)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data02-train1)\n",
    "ee2=MAE.mean()\n",
    "print(ee2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae215 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae215)\n",
    "mice_imputer = IterativeImputer()\n",
    "Z1= mice_imputer.fit_transform(data2)\n",
    "Z3=MinMaxScaler().fit_transform(Z1)\n",
    "MAE=np.abs(data02-Z3)\n",
    "ff2=MAE.mean()\n",
    "print(ff2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z3, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae216 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae216)\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "imputer = MissForest()\n",
    "X_imputed = imputer.fit_transform(dataa)\n",
    "data01=df1.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "X_imputed=MinMaxScaler().fit_transform(X_imputed)\n",
    "#data02=np.append(data01,data01,axis=1)\n",
    "MAE=np.abs(data01-X_imputed)\n",
    "gg2=MAE.mean()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae217 = mean_absolute_error(y_test, y_pred)\n",
    "print(gg2,mae217)\n",
    "import miceforest as mf\n",
    "import pandas as pd\n",
    "kernel = mf.ImputationKernel(\n",
    "  data=data,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "new_data = data.iloc[range(768)]\n",
    "new_data_imputed = kernel.impute_new_data(new_data)\n",
    "new_completed_data = new_data_imputed.complete_data(0)\n",
    "new_completed_data =MinMaxScaler().fit_transform(new_completed_data)\n",
    "MAE=np.abs(data01-new_completed_data)\n",
    "hh2=MAE.mean()\n",
    "print(hh2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_completed_data, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae218 = mean_absolute_error(y_test, y_pred)\n",
    "mae218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59c82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57493133 0.83333250 0.42857100 ... 0.66666600 0.99999900 0.39279667]\n",
      " [0.76048653 0.24999975 0.28571400 ... 0.00000000 0.99999900 0.99999900]\n",
      " [0.55555500 0.53066158 0.42857100 ... 0.66666600 0.51828431 0.48434315]\n",
      " ...\n",
      " [0.33333300 0.58333275 0.00000000 ... 0.11546499 0.24999975 0.79999920]\n",
      " [0.99999900 0.61894364 0.49678328 ... 0.00000000 0.99999900 0.42202400]\n",
      " [0.48326485 0.56102973 0.57142800 ... 0.33333300 0.47645620 0.48991613]]\n",
      "0.37615344787401833\n",
      "9.318347982463749\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)\n",
    "data1=df1.iloc[:,0:8]\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.3\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0\n",
    "\n",
    "#%% Data\n",
    "# Data generation\n",
    "Data = data01\n",
    "# Parameters\n",
    "Data = np.array(Data,type(float))\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "#%% 1. Discriminator\n",
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 2. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx\n",
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample\n",
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)\n",
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "M_mb = M_mb.astype(float)\n",
    "X_mb = testX\n",
    "X_mb = X_mb.astype(float)\n",
    "\n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "        \n",
    "#print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))\n",
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
    "#print(\"Imputed test data:\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "if use_gpu is True:\n",
    "    print(imputed_data.cpu().detach().numpy())\n",
    "else:\n",
    "    print(imputed_data.detach().numpy())\n",
    "A=imputed_data.detach().numpy()\n",
    "MAE=np.abs(data01-A)\n",
    "ii2=MAE.mean()\n",
    "print(ii2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(imputed_data.detach().numpy(), y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae219 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0632f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15603365553329443\n",
      "5.129026579923499\n",
      "0.016642123429232804\n",
      "2.37653374099159\n",
      "0.05313664756685322\n",
      "2.4068002628696483\n",
      "0.3294336830287173\n",
      "5.1721299524556095\n",
      "0.30447646045180227\n",
      "3.893745372675366\n",
      "0.35219235664505044\n",
      "3.9063070380721228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4\n",
      "0.04013169136383774 2.63279022384489\n",
      "0.040727629484953703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3715678936982307"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(\"energy.txt\",sep=\"\\s+\")\n",
    "datab=df2.iloc[:,0:8]\n",
    "y=df2.iloc[:,-1:]\n",
    "for col in datab :\n",
    "    datab.loc[datab.sample(frac=0.5,random_state=None).index, col] = np.nan\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "A2=imp.fit(datab)\n",
    "A2=imp.transform(datab)\n",
    "A2=MinMaxScaler().fit_transform(A2)\n",
    "data01=df2.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "MAE=np.abs(data01-A2)\n",
    "aa3=MAE.mean()\n",
    "print(aa3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(A2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae311 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae311)\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data01-train1)\n",
    "bb3=MAE.mean()\n",
    "print(bb3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae312 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae312)\n",
    "mice_imputer = IterativeImputer()\n",
    "A4= mice_imputer.fit_transform(data)\n",
    "A5=MinMaxScaler().fit_transform(A4)\n",
    "MAE=np.abs(data01-A5)\n",
    "cc3=MAE.mean()\n",
    "print(cc3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(A5, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae313 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae313)\n",
    "Z=datab.copy(deep=True)\n",
    "Z[Z>=0]=0\n",
    "Z[Z<0]=0\n",
    "Z=Z.fillna(value=1)\n",
    "data2=pd.concat([datab,Z],axis=1)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Z2=imp.fit(data2)\n",
    "Z2=imp.transform(data2)\n",
    "Z2=MinMaxScaler().fit_transform(Z2)\n",
    "data02=np.append(data01,data01,axis=1)\n",
    "MAE=np.abs(data02-Z2)\n",
    "dd3=MAE.mean()\n",
    "print(dd3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae314 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae314)\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data2)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data02-train1)\n",
    "ee3=MAE.mean()\n",
    "print(ee3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae315 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae315)\n",
    "mice_imputer = IterativeImputer()\n",
    "Z1= mice_imputer.fit_transform(data2)\n",
    "Z3=MinMaxScaler().fit_transform(Z1)\n",
    "MAE=np.abs(data02-Z3)\n",
    "ff3=MAE.mean()\n",
    "print(ff3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z3, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae316 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae316)\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "imputer = MissForest()\n",
    "X_imputed = imputer.fit_transform(dataa)\n",
    "data01=df2.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "X_imputed=MinMaxScaler().fit_transform(X_imputed)\n",
    "MAE=np.abs(data01-X_imputed)\n",
    "gg3=MAE.mean()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae317 = mean_absolute_error(y_test, y_pred)\n",
    "print(gg3,mae317)\n",
    "import miceforest as mf\n",
    "import pandas as pd\n",
    "kernel = mf.ImputationKernel(\n",
    "  data=data,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "new_data = data.iloc[range(768)]\n",
    "new_data_imputed = kernel.impute_new_data(new_data)\n",
    "new_completed_data = new_data_imputed.complete_data(0)\n",
    "new_completed_data =MinMaxScaler().fit_transform(new_completed_data)\n",
    "MAE=np.abs(data01-new_completed_data)\n",
    "hh3=MAE.mean()\n",
    "print(hh3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_completed_data, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae318 = mean_absolute_error(y_test, y_pred)\n",
    "mae318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b061370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19444425 0.74999925 0.28571400 ... 0.37555861 0.00000000 0.46194912]\n",
      " [0.38888850 0.49999950 0.53927706 ... 0.41046432 0.99999900 0.49746870]\n",
      " [0.53624861 0.91666575 0.57142800 ... 0.99999900 0.62499938 0.43456050]\n",
      " ...\n",
      " [0.51273033 0.36074299 0.42857100 ... 0.41172866 0.62499938 0.59999940]\n",
      " [0.48825631 0.99999900 0.49537319 ... 0.50090574 0.24999975 0.49205912]\n",
      " [0.77777700 0.29367394 0.60695540 ... 0.54045823 0.99999900 0.59999940]]\n",
      "0.35448583999077404\n",
      "9.336384870576214\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)\n",
    "data1=df2.iloc[:,0:8]\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.5\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0\n",
    "\n",
    "#%% Data\n",
    "# Data generation\n",
    "Data = data01\n",
    "# Parameters\n",
    "Data = np.array(Data,type(float))\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "#%% 1. Discriminator\n",
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 2. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx\n",
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample\n",
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)\n",
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "M_mb = M_mb.astype(float)\n",
    "X_mb = testX\n",
    "X_mb = X_mb.astype(float)\n",
    "\n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "        \n",
    "#print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))\n",
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
    "#print(\"Imputed test data:\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "if use_gpu is True:\n",
    "    print(imputed_data.cpu().detach().numpy())\n",
    "else:\n",
    "    print(imputed_data.detach().numpy())\n",
    "A=imputed_data.detach().numpy()\n",
    "MAE=np.abs(data01-A)\n",
    "ii3=MAE.mean()\n",
    "print(ii3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(imputed_data.detach().numpy(), y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae319 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b503ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21823544962312372\n",
      "6.16031251425128\n",
      "0.016642123429232804\n",
      "2.37653374099159\n",
      "0.05313664756685322\n",
      "2.4068002628696483\n",
      "0.3234652843845374\n",
      "5.105638255351397\n",
      "0.3154110378689236\n",
      "4.9081433018973195\n",
      "0.3464076032406438\n",
      "4.034884995918132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:388: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5\n",
      "0.039617329780807536 2.6568395911359803\n",
      "0.040727629484953703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3715678936982307"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_csv(\"energy.txt\",sep=\"\\s+\")\n",
    "datac=df3.iloc[:,0:8]\n",
    "y=df3.iloc[:,-1:]\n",
    "for col in datac :\n",
    "    datac.loc[datab.sample(frac=0.7,random_state=None).index, col] = np.nan\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "A2=imp.fit(datac)\n",
    "A2=imp.transform(datac)\n",
    "A2=MinMaxScaler().fit_transform(A2)\n",
    "data01=df3.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "MAE=np.abs(data01-A2)\n",
    "aa4=MAE.mean()\n",
    "print(aa4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(A2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae411 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae411)\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data01-train1)\n",
    "bb4=MAE.mean()\n",
    "print(bb4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae412 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae412)\n",
    "mice_imputer = IterativeImputer()\n",
    "A4= mice_imputer.fit_transform(data)\n",
    "A5=MinMaxScaler().fit_transform(A4)\n",
    "MAE=np.abs(data01-A5)\n",
    "cc4=MAE.mean()\n",
    "print(cc4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(A5, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae413 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae413)\n",
    "Z=datac.copy(deep=True)\n",
    "Z[Z>=0]=0\n",
    "Z[Z<0]=0\n",
    "Z=Z.fillna(value=1)\n",
    "data2=pd.concat([datab,Z],axis=1)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Z2=imp.fit(data2)\n",
    "Z2=imp.transform(data2)\n",
    "Z2=MinMaxScaler().fit_transform(Z2)\n",
    "data02=np.append(data01,data01,axis=1)\n",
    "MAE=np.abs(data02-Z2)\n",
    "dd4=MAE.mean()\n",
    "print(dd4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z2, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae414 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae414)\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train = knn_imputer.fit_transform(data2)\n",
    "train1=MinMaxScaler().fit_transform(train)\n",
    "MAE=np.abs(data02-train1)\n",
    "ee4=MAE.mean()\n",
    "print(ee4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae415 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae415)\n",
    "mice_imputer = IterativeImputer()\n",
    "Z1= mice_imputer.fit_transform(data2)\n",
    "Z3=MinMaxScaler().fit_transform(Z1)\n",
    "MAE=np.abs(data02-Z3)\n",
    "ff4=MAE.mean()\n",
    "print(ff4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z3, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae416 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae416)\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "imputer = MissForest()\n",
    "X_imputed = imputer.fit_transform(dataa)\n",
    "data01=df3.iloc[:,0:8]\n",
    "data01=MinMaxScaler().fit_transform(data01)\n",
    "X_imputed=MinMaxScaler().fit_transform(X_imputed)\n",
    "MAE=np.abs(data01-X_imputed)\n",
    "gg4=MAE.mean()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae417 = mean_absolute_error(y_test, y_pred)\n",
    "print(gg4,mae417)\n",
    "import miceforest as mf\n",
    "import pandas as pd\n",
    "kernel = mf.ImputationKernel(\n",
    "  data=data,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "new_data = data.iloc[range(768)]\n",
    "new_data_imputed = kernel.impute_new_data(new_data)\n",
    "new_completed_data = new_data_imputed.complete_data(0)\n",
    "new_completed_data =MinMaxScaler().fit_transform(new_completed_data)\n",
    "MAE=np.abs(data01-new_completed_data)\n",
    "hh4=MAE.mean()\n",
    "print(hh4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_completed_data, y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae418 = mean_absolute_error(y_test, y_pred)\n",
    "mae418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3bbbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19444425 0.74999925 0.58731320 ... 0.34028426 0.62499938 0.79999920]\n",
      " [0.42859662 0.30738632 0.55302461 ... 0.38901539 0.62499938 0.59413455]\n",
      " [0.33333300 0.58333275 0.49835060 ... 0.49992605 0.50949664 0.51854733]\n",
      " ...\n",
      " [0.05555550 0.41053965 0.44091794 ... 0.33333300 0.24999975 0.55011434]\n",
      " [0.49990639 0.49932260 0.50055502 ... 0.49952582 0.49965621 0.50121482]\n",
      " [0.49957010 0.49928790 0.50106811 ... 0.49928254 0.49932737 0.50170875]]\n",
      "0.34181918406957923\n",
      "9.2129550528093\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)\n",
    "data1=df3.iloc[:,0:8]\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.7\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0\n",
    "\n",
    "#%% Data\n",
    "# Data generation\n",
    "Data = data01\n",
    "# Parameters\n",
    "Data = np.array(Data,type(float))\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C\n",
    "#%% 1. Discriminator\n",
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 2. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx\n",
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample\n",
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)\n",
    "Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = testM\n",
    "M_mb = M_mb.astype(float)\n",
    "X_mb = testX\n",
    "X_mb = X_mb.astype(float)\n",
    "\n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "        \n",
    "#print('Final Test RMSE: ' + str(np.sqrt(MSE_final.item())))\n",
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample\n",
    "#print(\"Imputed test data:\")\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})\n",
    "\n",
    "if use_gpu is True:\n",
    "    print(imputed_data.cpu().detach().numpy())\n",
    "else:\n",
    "    print(imputed_data.detach().numpy())\n",
    "A=imputed_data.detach().numpy()\n",
    "MAE=np.abs(data01-A)\n",
    "ii4=MAE.mean()\n",
    "print(ii4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(imputed_data.detach().numpy(), y, test_size=0.3, random_state=0)\n",
    "reg_all = LinearRegression()\n",
    "reg_all.fit(X_train,y_train)\n",
    "y_pred = reg_all.predict(X_test)\n",
    "score = reg_all.score(X_test, y_test)\n",
    "mae419 = mean_absolute_error(y_test, y_pred)\n",
    "print(mae419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02965c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab\n",
    "N=[0.1,0.3,0.5,0.7]\n",
    "M1=[aa,aa2,aa3,aa4]\n",
    "M2=[bb,bb2,bb3,bb4]\n",
    "M3=[cc,cc2,cc3,cc4]\n",
    "M4=[dd,dd2,dd3,dd4]\n",
    "M5=[ee,ee2,ee3,ee4]\n",
    "M6=[ff,ff2,ff3,ff4]\n",
    "M7=[gg,gg2,gg3,gg4]\n",
    "M8=[hh,hh2,hh3,hh4]\n",
    "M9=[ii,ii2,ii3,ii4]\n",
    "plt.xlim([0.1,0.7])\n",
    "plt.xticks(np.arange(0.1,0.9,0.2))# x軸邊界\n",
    "plt.xlabel('Missing Data Ratio')\n",
    "plt.ylabel('Missing Value Imputation Ratio--MAE')\n",
    "plt.title('energy')\n",
    "plt.plot(N,M1,label='mean')\n",
    "plt.plot(N,M2,label='knn')\n",
    "plt.plot(N,M3,label='mice')\n",
    "plt.plot(N,M4,label='meanmi')\n",
    "plt.plot(N,M5,label='knnmi')\n",
    "plt.plot(N,M6,label='micemi')\n",
    "plt.plot(N,M7,label='missforest')\n",
    "plt.plot(N,M8,label='miceforest')\n",
    "plt.plot(N,M9,label='gain')\n",
    "plt.legend(loc='best')\n",
    "figsize(6,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b83f9c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab\n",
    "N=[0.1,0.3,0.5,0.7]\n",
    "M1=[mae11,mae211,mae311,mae411]\n",
    "M2=[mae12,mae212,mae312,mae412]\n",
    "M3=[mae13,mae213,mae313,mae413]\n",
    "M4=[mae14,mae214,mae314,mae414]\n",
    "M5=[mae15,mae215,mae315,mae415]\n",
    "M6=[mae16,mae216,mae316,mae416]\n",
    "M7=[mae17,mae217,mae317,mae417]\n",
    "M8=[mae18,mae218,mae318,mae418]\n",
    "M9=[mae19,mae219,mae319,mae419]\n",
    "plt.xlim([0,0.8])\n",
    "plt.xticks(np.arange(0.1,0.9,0.2))# x軸邊界\n",
    "plt.xlabel('Missing Data Ratio')\n",
    "plt.ylabel('Target Regression Prediction Test--MAE')\n",
    "plt.title('energy')\n",
    "plt.plot(N,M1,label='mean')\n",
    "plt.plot(N,M2,label='knn')\n",
    "plt.plot(N,M3,label='mice')\n",
    "plt.plot(N,M4,label='meanmi')\n",
    "plt.plot(N,M5,label='knnmi')\n",
    "plt.plot(N,M6,label='micemi')\n",
    "plt.plot(N,M7,label='missforest')\n",
    "plt.plot(N,M8,label='miceforest')\n",
    "plt.plot(N,M9,label='gain')\n",
    "plt.legend(loc='best')\n",
    "figsize(5,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a417a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
